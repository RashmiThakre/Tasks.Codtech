{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR2H75hgrhaOjcZr+i5uq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RashmiThakre/Tasks.Codtech/blob/main/Task4_Codtech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx7Df-IhGKni",
        "outputId": "40d2fd08-3843-4552-a73f-ed57aef6aa1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/archive (2).zip')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScnJDKgFGOp5",
        "outputId": "fce15d89-f31e-4571-a1a7-6b4a94cc6ed9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       textID                                               text  \\\n",
            "0  cb774db0d1                I`d have responded, if I were going   \n",
            "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
            "2  088c60f138                          my boss is bullying me...   \n",
            "3  9642c003ef                     what interview! leave me alone   \n",
            "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
            "\n",
            "                         selected_text sentiment  \n",
            "0  I`d have responded, if I were going   neutral  \n",
            "1                             Sooo SAD  negative  \n",
            "2                          bullying me  negative  \n",
            "3                       leave me alone  negative  \n",
            "4                        Sons of ****,  negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the Text Data\n",
        "# Define a function to clean and preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Handle non-string values\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Return an empty string for non-string values\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "    # Remove special characters, numbers, and punctuations\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back into a single string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the preprocessing function to the text column\n",
        "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Display the cleaned text\n",
        "print(df[['text', 'cleaned_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpzLlomGG7NR",
        "outputId": "4aa5e514-2c84-4604-aa66-a353ab7b2f08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0                I`d have responded, if I were going   \n",
            "1      Sooo SAD I will miss you here in San Diego!!!   \n",
            "2                          my boss is bullying me...   \n",
            "3                     what interview! leave me alone   \n",
            "4   Sons of ****, why couldn`t they put them on t...   \n",
            "\n",
            "                             cleaned_text  \n",
            "0                      id responded going  \n",
            "1                 sooo sad miss san diego  \n",
            "2                            bos bullying  \n",
            "3                   interview leave alone  \n",
            "4  son couldnt put release already bought  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Sentiment Scores\n",
        "# Define a function to get sentiment polarity\n",
        "def get_sentiment(text):\n",
        "    sentiment = TextBlob(text).sentiment.polarity\n",
        "    return sentiment\n",
        "\n",
        "# Apply the sentiment analysis function\n",
        "df['sentiment'] = df['cleaned_text'].apply(get_sentiment)\n",
        "\n",
        "# Display the sentiment scores\n",
        "print(df[['cleaned_text', 'sentiment']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPQAsXwDIFjC",
        "outputId": "38bb330e-14d6-4495-8a22-dfc07045305f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             cleaned_text  sentiment\n",
            "0                      id responded going        0.0\n",
            "1                 sooo sad miss san diego       -0.5\n",
            "2                            bos bullying        0.0\n",
            "3                   interview leave alone        0.0\n",
            "4  son couldnt put release already bought        0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize Sentiment Trends Over Time\n",
        "if 'date' in df.columns:\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # Group the data by date and calculate the average sentiment per day\n",
        "    sentiment_trend = df.groupby(df['date'].dt.date)['sentiment'].mean().reset_index()\n",
        "\n",
        "    # Plot the sentiment trend over time\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(x='date', y='sentiment', data=sentiment_trend, marker='o')\n",
        "    plt.title('Sentiment Trend Over Time')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Average Sentiment Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: 'date' column not found in the DataFrame. Please check your column names.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNmyq4F1IQ91",
        "outputId": "89eb427d-f11a-47a6-9467-65c0bb434fb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'date' column not found in the DataFrame. Please check your column names.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWQX3fN1GOu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}